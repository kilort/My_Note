

一 异常（Exceptions）

 scrapy的内置异常处理并不多，主要有一下几种：（× ： 常用）
         × 1.DropItem  ：  运用于item pipline当中,根据条件判断.将此item抛出循环，
         × 2.CloseSpider： 该异常用于spider的回调函数抛出,来暂停spider（支持的参数：reason）
                           例子：  def parse_page(self, response):
                                    if 'Bandwidth exceeded' in response.body:
                                    raise CloseSpider('bandwidth_exceeded')
           3.IgnoreRequest ： 该异常有调度器或者中间件抛出,声明忽略该request
         × 4.NotConfigured :  该异常由某些组件抛出,声明其仍保持关闭,这些组件有：Extensions,Item pipelines,Downloader middlwares,Spider middlewares
           5.NotSupported  :  该异常声明一个不支持的特性。




二 数据收集（stats collection）（不太懂其功能）
   以键值对的方式存储,值是计数值,这种机制叫做数据收集器。无论数据收集开启或者关闭,数据收集器永远是可用的,数据收集器其在spider开启时,自动打开,关闭时,自动关闭。


三 发送email
   scrapy有自带的scrapy的email的发送方式。
   有俩种方式可以构建邮件发送器：
   1.from scrapy.mail import MailSender
     mailer = MailSender()
     mailer.send(to=["someone@example.com"], subject="Some subject", body="Some body", cc=["another@example.com"]

   2.mailer = MailSender.from_settings(settings)
     mailer.send(to=["someone@example.com"], subject="Some subject", body="Some body", cc=["another@example.com"]
     mail的设置（定义了MailSender构造器的默认值.其使得不写一行代码的亲款下,实现项目的配置实现email的通知功能）：
     MAIL_FROM  默认值: 'scrapy@localhost'，用于发送email的地址(address)(填入 From:) 。
     MAIL_HOST，默认值: 'localhost'，发送email的SMTP主机(host)。
     MAIL_PORT，默认值: 25，发用邮件的SMTP端口。
     MAIL_USER，默认值: None，SMTP用户。如果未给定，则将不会进行SMTP认证(authentication)。
     MAIL_PASS，默认值: None，用于SMTP认证，与 MAIL_USER 配套的密码。
     MAIL_TLS，默认值: False，强制使用STARTTLS。STARTTLS能使得在已经存在的不安全连接上，通过使用SSL/TLS来实现安全连接。
     MAIL_SSL，默认值: False，强制使用SSL加密连接。

四 web service
   scrapy提供的一个控制和监控运行中爬虫的web服务（service），服务通过 JSON-RPC 2.0 协议提供大部分的资源，不过也有些(只读)资源仅仅输出JSON数据。
   Scrapy为管理Scrapy进程提供了一个可扩展的web服务。 您可以通过 WEBSERVICE_ENABLED 来启用服务。 服务将会监听 WEBSERVICE_PORT 的端口，并将记录写入到 WEBSERVICE_LOGFILE 指定的文件中。
   web服务是默认启用的 内置Scrapy扩展 ， 不过如果您运行的环境内存紧张的话，也可以关闭该扩展。

web service资源
   web service提供多种资源，定义在 WEBSERVICE_RESOURCES 设置中。 每个资源提供了不同的功能。参考 可用JSON-RPC对象 来查看默认可用的资源。
   虽然您可以使用任何协议来实现您的资源，但有两种资源是和Scrapy绑定的:
                Simple JSON resources - 只读，输出JSON数据
                JSON-RPC resources - 通过使用 JSON-RPC 2.0 协议支持对一些Scrapy对象的直接访问

可用的json-rpc对象
   Crawler JSON-RPC资源:提供对主Crawler对象的访问，来控制Scrapy进程。默认访问地址: http://localhost:6080/crawler
   状态收集器(Stats Collector)JSON-RPC资源:提供对crawler使用的状态收集器(Stats Collector)的访问。默认访问地址: http://localhost:6080/stats
   爬虫管理器(Spider Manager)JSON-RPC资源 : 您可以通过 Crawler JSON-RPC资源 来访问 爬虫管理器JSON-RPC资源。地址为: http://localhost:6080/crawler/spiders
   扩展管理器(Extension Manager)JSON-RPC资源 :您可以通过 Crawler JSON-RPC资源 来访问 扩展管理器JSON-RPC资源。

可用JSON资源
   引擎状态JSON资源:提供了对引擎状态数据的访问,默认访问地址: http://localhost:6080/enginestatus

web服务设置：见settings中关于web的设置部分























